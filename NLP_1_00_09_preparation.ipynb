{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 言語処理100本ノック"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://nlp100.github.io/ja/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第１章:準備運動　00~09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリインポート\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 00. 文字列の逆順\n",
    "##### 文字列”stressed”の文字を逆に（末尾から先頭に向かって）並べた文字列を得よ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desserts\n"
     ]
    }
   ],
   "source": [
    "hoge = \"stressed\"\n",
    "result = hoge[::-1]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. 「パタトクカシーー」\n",
    "##### 「パタトクカシーー」という文字列の1,3,5,7文字目を取り出して連結した文字列を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パトカー\n"
     ]
    }
   ],
   "source": [
    "hoge = \"パタトクカシーー\"\n",
    "result = hoge[0:10:2]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "タクシー\n"
     ]
    }
   ],
   "source": [
    "hoge = \"パタトクカシーー\"\n",
    "result = hoge[1:10:2]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. 「パトカー」＋「タクシー」＝「パタトクカシーー」\n",
    "##### 「パトカー」＋「タクシー」の文字を先頭から交互に連結して文字列「パタトクカシーー」を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パタトクカシーー\n"
     ]
    }
   ],
   "source": [
    "pat = \"パトカー\"\n",
    "tax = \"タクシー\"\n",
    "result=\"\"\n",
    "i=0\n",
    "for i,j in zip(pat, tax):\n",
    "    result = result+i+j\n",
    "    \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03. 円周率\n",
    "##### “Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.”という文を単語に分解し，各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314159265358979\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.'\n",
    "result=''\n",
    "\n",
    "#不要文字削除\n",
    "sentence = sentence.replace(\",\", \"\")\n",
    "sentence = sentence.replace(\".\",\"\")\n",
    "#文字列をスペースで分割\n",
    "sentence = sentence.split(' ')\n",
    "\n",
    "for term in sentence:\n",
    "    result=result+str(len(term))\n",
    "    \n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04. 元素記号\n",
    "##### “Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.”という文を単語に分解し，1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字，それ以外の単語は先頭に2文字を取り出し，取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'Hi', 2: 'He', 3: 'Li', 4: 'Be', 5: 'Bo', 6: 'Co', 7: 'No', 8: 'Ox', 9: 'Fl', 10: 'Ne', 11: 'Na', 12: 'Mi', 13: 'Al', 14: 'Si', 15: 'Pe', 16: 'Se', 17: 'Cl', 18: 'Ar', 19: 'Ki', 20: 'Ca'}\n"
     ]
    }
   ],
   "source": [
    "sentence=\"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "result={}\n",
    "\n",
    "#不要文字削除\n",
    "sentence = sentence.replace(\",\", \"\")\n",
    "sentence = sentence.replace(\".\",\"\")\n",
    "#文字列をスペースで分割\n",
    "sentence = sentence.split(' ')\n",
    "\n",
    "i=0\n",
    "for term in sentence:\n",
    "    i=i+1\n",
    "    if i == {1,5,6,7,8,9,15,16,19}:\n",
    "        result[i] = term[0]\n",
    "    else:\n",
    "        result[i] = term[0:2]\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05. n-gram\n",
    "##### 与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ．この関数を用い，”I am an NLPer”という文から単語bi-gram，文字bi-gramを得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#単語n-gram\n",
    "def n_gram_term(n,sentence):\n",
    "    result = []\n",
    "    #不要文字削除\n",
    "    sentence = sentence.replace(\",\", \"\")\n",
    "    sentence = sentence.replace(\".\",\"\")\n",
    "    #文字列をスペースで分割\n",
    "    sentence = sentence.split(' ')\n",
    "    \n",
    "    for i in range(len(sentence) - n + 1):\n",
    "        result.append(sentence[i:i+n])\n",
    "\n",
    "    return result\n",
    "\n",
    "#文字n-gram\n",
    "def n_gram_letter(n,sentence):\n",
    "    result = []\n",
    "    #不要文字削除\n",
    "    sentence = sentence.replace(\",\", \"\")\n",
    "    sentence = sentence.replace(\".\",\"\")\n",
    "    sentence = sentence.replace(\" \",\"\")\n",
    "    \n",
    "    for i in range(len(sentence) - n + 1):\n",
    "        result.append(sentence[i:i + n])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'am'], ['am', 'an'], ['an', 'NLPer']]\n",
      "['Ia', 'am', 'ma', 'an', 'nN', 'NL', 'LP', 'Pe', 'er']\n"
     ]
    }
   ],
   "source": [
    "sentence='I am an NLPer'\n",
    "#単語bi-gram\n",
    "res_term = n_gram_term(2,sentence)\n",
    "print(res_term)\n",
    "\n",
    "#文字bi-gram\n",
    "res_letter =n_gram_letter(2,sentence)\n",
    "print(res_letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 06. 集合\n",
    "##### “paraparaparadise”と”paragraph”に含まれる文字bi-gramの集合を，それぞれ, XとYとして求め，XとYの和集合，積集合，差集合を求めよ．さらに，’se’というbi-gramがXおよびYに含まれるかどうかを調べよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:{'ra', 'pa', 'is', 'di', 'ar', 'se', 'ad', 'ap'}\n",
      "Y:{'ra', 'pa', 'gr', 'ph', 'ap', 'ar', 'ag'}\n",
      "Union:{'ag', 'ra', 'pa', 'is', 'di', 'gr', 'ph', 'ar', 'se', 'ad', 'ap'}\n",
      "Intersection:{'ar', 'ra', 'pa', 'ap'}\n",
      "DefferenceSet_X:{'se', 'is', 'di', 'ad'}\n",
      "DefferenceSet_Y:{'gr', 'ph', 'ag'}\n",
      "SymDefferenceSet_X:{'is', 'di', 'gr', 'ph', 'se', 'ad', 'ag'}\n",
      "SymDefferenceSet_Y:{'is', 'di', 'gr', 'ph', 'se', 'ad', 'ag'}\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "sen_x= \"paraparaparadise\"\n",
    "sen_y= \"paragraph\"\n",
    "\n",
    "X=set(n_gram_letter(2,sen_x))\n",
    "Y=set(n_gram_letter(2,sen_y))\n",
    "\n",
    "print('X:'+str(X))\n",
    "print('Y:'+str(Y))\n",
    "\n",
    "#和集合\n",
    "Union=X | Y\n",
    "print('Union:'+str(Union))\n",
    "\n",
    "#積集合\n",
    "Intersection=X & Y\n",
    "print('Intersection:'+str(Intersection))\n",
    "\n",
    "#差集合\n",
    "DefferenceSet_X= X.difference(Y)\n",
    "DefferenceSet_Y= Y.difference(X)\n",
    "print('DefferenceSet_X:'+str(DefferenceSet_X))\n",
    "print('DefferenceSet_Y:'+str(DefferenceSet_Y))\n",
    "\n",
    "#対象差集合\n",
    "SymmetricDeffereceSet_X= X.symmetric_difference(Y)\n",
    "SymmetricDeffereceSet_Y= Y.symmetric_difference(X)\n",
    "print('SymDefferenceSet_X:'+str(SymmetricDeffereceSet_X))\n",
    "print('SymDefferenceSet_Y:'+str(SymmetricDeffereceSet_Y))\n",
    "\n",
    "#se\n",
    "print(\"se\" in X)\n",
    "print(\"se\" in Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 07. テンプレートによる文生成\n",
    "##### 引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ．さらに，x=12, y=”気温”, z=22.4として，実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyz(x,y,z):\n",
    "    result=str(x)+'時の'+str(y)+'は'+str(z)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12時の気温は22.4'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=12\n",
    "y='気温'\n",
    "z=22.4\n",
    "mojiretu=xyz(x,y,z)\n",
    "mojiretu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 08. 暗号文\n",
    "##### 与えられた文字列の各文字を，以下の仕様で変換する関数cipherを実装せよ．\n",
    "\n",
    "- 英小文字ならば(219 - 文字コード)の文字に置換\n",
    "- その他の文字はそのまま出力\n",
    "\n",
    "##### この関数を用い，英語のメッセージを暗号化・復号化せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cipher(sentence):\n",
    "    result=''\n",
    "    for i in range(0,len(sentence)):\n",
    "        #1文字ずつ取り出し\n",
    "        s=sentence[i:i+1]\n",
    "        #小文字だけ変換\n",
    "        if s.islower():\n",
    "            s=chr(219 - ord(s))\n",
    "        \n",
    "        result=result+s\n",
    "    return result\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I zn zm NLPvi'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence='I am an NLPer'\n",
    "res=cipher(sentence)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 09. Typoglycemia\n",
    "##### スペースで区切られた単語列に対して，各単語の先頭と末尾の文字は残し，それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ．ただし，長さが４以下の単語は並び替えないこととする．適当な英語の文（例えば”I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .”）を与え，その実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def typoglycemia(sentence):\n",
    "    result_list = []\n",
    "\n",
    "    #不要文字削除\n",
    "    sentence = sentence.replace(\",\", \"\")\n",
    "    sentence = sentence.replace(\".\",\"\")\n",
    "\n",
    "    #文字列をスペースで分割\n",
    "    sentence = sentence.split(' ')\n",
    "\n",
    "    for term in sentence:\n",
    "        if len(term)>4:\n",
    "            #はじめの文字\n",
    "            initial=term[0]\n",
    "            #最後の文字\n",
    "            last=term[-1]\n",
    "            #中間の文字\n",
    "            middle = term[1:-1]\n",
    "            middle = random.sample(middle, len(middle))\n",
    "            middle=''.join(middle)\n",
    "            #単語書き直し\n",
    "            term=initial+middle+last\n",
    "        #リストとして単語格納\n",
    "        result_list.append(term)\n",
    "    #リストの要素を空白で連結\n",
    "    result=' '.join(result_list)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I codnl’ut bveeile that I colud aatuclly undntearsd what I was rdneiag : the pmoaeehnnl poewr of the hmuan mind'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence='I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind'\n",
    "res=typoglycemia(sentence)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
